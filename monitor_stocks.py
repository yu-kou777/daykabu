import yfinance as yf
import pandas as pd
import requests
import time
import os
import io
from datetime import datetime, timedelta, timezone

# --- è¨­å®š ---
DISCORD_WEBHOOK_URL = "https://discordapp.com/api/webhooks/1472281747000393902/Fbclh0R3R55w6ZnzhenJ24coaUPKy42abh3uPO-fRjfQulk9OwAq-Cf8cJQOe2U4SFme"
LIST_FILE = "prime_list.csv"

def calculate_rci(series, period):
    n = period
    rank_period = pd.Series(range(n, 0, -1))
    def rci_func(x):
        d = ((pd.Series(x).rank(ascending=False) - rank_period)**2).sum()
        return (1 - (6 * d) / (n * (n**2 - 1))) * 100
    return series.rolling(window=n).apply(rci_func)

def update_and_load_list():
    """ãƒªã‚¹ãƒˆãŒãªã‘ã‚Œã°ãƒãƒƒãƒˆã‹ã‚‰å–å¾—ã—ã¦ä¿å­˜ã€ã‚ã‚Œã°èª­ã¿è¾¼ã‚€"""
    if os.path.exists(LIST_FILE):
        print(f"ğŸ“ ä¿å­˜æ¸ˆã¿ã® {LIST_FILE} ã‚’èª­ã¿è¾¼ã¿ã¾ã™...")
        df = pd.read_csv(LIST_FILE)
        return {f"{int(row['ã‚³ãƒ¼ãƒ‰'])}.T": row['éŠ˜æŸ„å'] for _, row in df.iterrows()}
    
    print("ğŸ“¡ ãƒªã‚¹ãƒˆãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚JPXã‹ã‚‰æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦ä½œæˆã—ã¾ã™...")
    url = "https://www.jpx.co.jp/markets/statistics-banner/quote/01_data_j.xls"
    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        resp = requests.get(url, headers=headers, timeout=15)
        df_jpx = pd.read_excel(io.BytesIO(resp.content))
        prime_df = df_jpx[df_jpx['å¸‚å ´ãƒ»å•†å“åŒºåˆ†'].str.contains('ãƒ—ãƒ©ã‚¤ãƒ ', na=False)]
        save_df = prime_df[['ã‚³ãƒ¼ãƒ‰', 'éŠ˜æŸ„å']].copy()
        save_df.to_csv(LIST_FILE, index=False)
        print(f"âœ… {LIST_FILE} ã‚’ä½œæˆãƒ»ä¿å­˜ã—ã¾ã—ãŸã€‚")
        return {f"{int(row['ã‚³ãƒ¼ãƒ‰'])}.T": row['éŠ˜æŸ„å'] for _, row in save_df.iterrows()}
    except Exception as e:
        print(f"âŒ ãƒªã‚¹ãƒˆä½œæˆå¤±æ•—: {e}")
        return {"9101.T": "æ—¥æœ¬éƒµèˆ¹", "6481.T": "THK"} # æœ€çµ‚ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—

if __name__ == "__main__":
    jst = timezone(timedelta(hours=9))
    now_str = datetime.now(jst).strftime('%H:%M')
    
    # 1. ãƒªã‚¹ãƒˆã®è‡ªå‹•ç®¡ç†
    ticker_map = update_and_load_list()
    ticker_list = list(ticker_map.keys())
    
    requests.post(DISCORD_WEBHOOK_URL, json={"content": f"ğŸš€ **å“¨æˆ’é–‹å§‹(å…¨{len(ticker_list)}éŠ˜æŸ„)** ({now_str})"})

    # 2. ä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆã“ã‚ŒãŒä¸€ç•ªé€Ÿã„ï¼‰
    all_data = yf.download(ticker_list, period="6mo", interval="1d", group_by='ticker', threads=True)

    found_count = 0
    for ticker in ticker_list:
        try:
            df = all_data[ticker].dropna()
            if len(df) < 26: continue

            # ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«è§£æ
            df['MA25'] = df['Close'].rolling(window=25).mean()
            curr_p = df['Close'].iloc[-1]
            kairi = ((curr_p - df['MA25'].iloc[-1]) / df['MA25'].iloc[-1]) * 100
            df['RCI9'] = calculate_rci(df['Close'], 9)
            df['RCI26'] = calculate_rci(df['Close'], 26)
            curr, prev = df.iloc[-1], df.iloc[-2]

            # åˆ¤å®šæ¡ä»¶ï¼ˆÂ±10%ä¹–é›¢ ï¼‹ RCIã‚¯ãƒ­ã‚¹ï¼‰
            if (kairi <= -10.0 and curr['RCI9'] > curr['RCI26'] and curr['RCI9'] > prev['RCI9']) or \
               (kairi >= 10.0 and curr['RCI9'] < curr['RCI26'] and curr['RCI9'] < prev['RCI9']):
                
                found_count += 1
                type_str = "âš¡ã€åç™ºæœŸå¾…ã€‘" if kairi < 0 else "ğŸš€ã€é«˜å€¤è­¦æˆ’ã€‘"
                content = (
                    f"ğŸ¦… **{type_str}**\n**{ticker_map[ticker.replace('.T','')]}({ticker})**\n"
                    f"â”” ä¾¡æ ¼: {int(curr_p)}å†† / ä¹–é›¢: {round(kairi, 1)}%\n"
                    f"â”” RCI9: {round(curr['RCI9'], 1)}"
                )
                requests.post(DISCORD_WEBHOOK_URL, json={"content": content})
                time.sleep(1)
        except:
            continue

    requests.post(DISCORD_WEBHOOK_URL, json={"content": f"âœ… **å“¨æˆ’å®Œäº†** ({now_str}) åˆè‡´: {found_count}ä»¶"})
