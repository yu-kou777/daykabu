import yfinance as yf
import pandas as pd
import pandas_ta as ta
import requests
import time
import io
import os
from datetime import datetime, timedelta, timezone

# --- è¨­å®šï¼ˆURLä¿®æ­£æ¸ˆã¿ï¼‰ ---
DISCORD_WEBHOOK_URL = "https://discordapp.com/api/webhooks/1472281747000393902/Fbclh0R3R55w6ZnzhenJ24coaUPKy42abh3uPO-fRjfQulk9OwAq-Cf8cJQOe2U4SFme"

def calculate_rci(series, period):
    n = period
    rank_period = pd.Series(range(n, 0, -1))
    def rci_func(x):
        d = ((pd.Series(x).rank(ascending=False) - rank_period)**2).sum()
        return (1 - (6 * d) / (n * (n**2 - 1))) * 100
    return series.rolling(window=n).apply(rci_func)

def is_peak_down(series):
    """å±±(ãƒ”ãƒ¼ã‚¯)åˆ¤å®š"""
    if len(series) < 4: return False
    return (series.iloc[-2] > series.iloc[-3]) and (series.iloc[-2] > series.iloc[-1])

def is_trough_up(series):
    """è°·(ãƒœãƒˆãƒ )åˆ¤å®š"""
    if len(series) < 4: return False
    return (series.iloc[-2] < series.iloc[-3]) and (series.iloc[-2] < series.iloc[-1])

def get_latest_prime_list():
    """JPXã‹ã‚‰æœ€æ–°ã®ãƒ—ãƒ©ã‚¤ãƒ å…¨éŠ˜æŸ„ãƒªã‚¹ãƒˆã‚’å–å¾—ï¼ˆè¤‡æ•°URLå¯¾å¿œï¼‰"""
    urls = [
        "https://www.jpx.co.jp/markets/statistics-banner/quote/01_data_j.xls",
        "https://www.jpx.co.jp/markets/statistics-banner/quote/tvdivq0000001vg2-att/data_j.xls"
    ]
    headers = {"User-Agent": "Mozilla/5.0"}
    for url in urls:
        try:
            resp = requests.get(url, headers=headers, timeout=15)
            if resp.status_code == 200:
                df_jpx = pd.read_excel(io.BytesIO(resp.content))
                prime_df = df_jpx[df_jpx['å¸‚å ´ãƒ»å•†å“åŒºåˆ†'].str.contains('ãƒ—ãƒ©ã‚¤ãƒ ', na=False)]
                return {f"{int(row['ã‚³ãƒ¼ãƒ‰'])}.T": row['éŠ˜æŸ„å'] for _, row in prime_df.iterrows()}
        except:
            continue
    # ä¸‡ãŒä¸€ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
    return {"9101.T": "æ—¥æœ¬éƒµèˆ¹", "6481.T": "THK", "7203.T": "ãƒˆãƒ¨ã‚¿"}

if __name__ == "__main__":
    jst = timezone(timedelta(hours=9))
    now_str = datetime.now(jst).strftime('%H:%M')
    
    ticker_map = get_latest_prime_list()
    ticker_list = list(ticker_map.keys())
    
    # æœ€åˆã®é€šçŸ¥ãŒå±Šã‘ã°ã€URLè¨­å®šã¯æˆåŠŸã§ã™ï¼
    requests.post(DISCORD_WEBHOOK_URL, json={"content": f"ğŸš€ **ãƒ—ãƒ©ã‚¤ãƒ å¸‚å ´({len(ticker_list)}ç¤¾) å“¨æˆ’é–‹å§‹** ({now_str})"})

    # 1600ä»¶ã‚’ä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    all_data = yf.download(ticker_list, period="6mo", interval="1d", group_by='ticker', threads=True)

    found_count = 0
    for ticker in ticker_list:
        try:
            df = all_data[ticker].dropna()
            if len(df) < 30: continue

            df.ta.rsi(length=14, append=True)
            df['RCI9'] = calculate_rci(df['Close'], 9)
            df['RCI26'] = calculate_rci(df['Close'], 26)
            
            curr, prev = df.iloc[-1], df.iloc[-2]

            # åŒæœŸãƒ”ãƒ¼ã‚¯åˆ¤å®š
            peak_down = is_peak_down(df['RSI_14']) and is_peak_down(df['RCI9'])
            trough_up = is_trough_up(df['RSI_14']) and is_trough_up(df['RCI9'])
            
            # RCIã‚¯ãƒ­ã‚¹åˆ¤å®š
            gc = (prev['RCI9'] <= prev['RCI26']) and (curr['RCI9'] > curr['RCI26'])
            dc = (prev['RCI9'] >= prev['RCI26']) and (curr['RCI9'] < curr['RCI26'])

            signal = None
            reason = []
            if peak_down or dc:
                signal = "ğŸ”»ã€å£²ã‚Šè­¦æˆ’ã€‘"
                if peak_down: reason.append("RSI/RCIåŒæœŸå±±")
                if dc: reason.append("RCIãƒ‡ãƒƒãƒ‰ã‚¯ãƒ­ã‚¹")
            elif trough_up or gc:
                signal = "ğŸ”¥ã€è²·ã„æ¤œè¨ã€‘"
                if trough_up: reason.append("RSI/RCIåŒæœŸè°·")
                if gc: reason.append("RCIã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ã‚¯ãƒ­ã‚¹")

            if signal:
                found_count += 1
                content = (
                    f"ğŸ¦… **{signal}**\n**{ticker_map[ticker.replace('.T','')]}({ticker})**\n"
                    f"â”” ä¾¡æ ¼: {int(curr['Close'])}å†† / RSI: {round(curr['RSI_14'], 1)}\n"
                    f"â”” ç†ç”±: {' / '.join(reason)}"
                )
                requests.post(DISCORD_WEBHOOK_URL, json={"content": content})
                time.sleep(0.5)
        except:
            continue

    requests.post(DISCORD_WEBHOOK_URL, json={"content": f"âœ… **å“¨æˆ’å®Œäº†** åˆè‡´: {found_count}ä»¶"})
